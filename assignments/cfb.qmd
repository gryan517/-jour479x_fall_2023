```{r}
library(tidyverse)
library(cfbfastR)
library(Hmisc)
library(ggbump)
```


```{r}
plays_2023 <- cfbd_pbp_data(2023)
```
Detail example: it appears that teams are inconsistent about how they define the first play. Many use the kickoff as the first play while some do not.

```{r}
plays_2023 |> filter(drive_number == 1, play_number == 1, play_type != 'Kickoff') |> distinct(home, play_type)
```




##College Football Game Data Analysis

```{r}
logs <- read_csv ("https://dwillis.github.io/sports-data-files/footballlogs1122.csv")
```
```{r}
newlogs <- logs |> 
  mutate(
    differential = abs(TeamScore - OpponentScore)
    )
```

```{r}
newlogs |> 
  summarise(correlation = cor(Penalties, differential, method="pearson"))
```
```{r}
fit <- lm(differential ~ Penalties, data = newlogs)
summary(fit)
```
p-value: looking at the p-value, 0.01058, it is less than .05 which indicates that the relationship in this model between the differential score and penalties is statistically significant. This indicates that the results are not random. 

Adjusted R-squared: the adjusted R-square indicates that .03 percent of the score differential can be explained by the penalties. This means that this is likely not a useful regression.


##College Football Game Data Analysis (part 2)
```{r}
simplelogs <- logs |> 
  select_if(is.numeric) |> select(-Game) |> select(differential, Penalties, Fumbles, TurnoverMargin, Intercepts, Rushing, PenYds)
```

```{r}
cormatrix <- rcorr(as.matrix(simplelogs))

cormatrix$r
```
Fumbles and turnover have a high correlation, which makes sense since fumbles likely lead to turnovers. 

PenYds has a very low correlation in the model, which tells me that this aspect wouldn't effect the scoring as much in the model (effect residual by 0.1)


```{r}
newlogs <- logs |> mutate(
  differential = TeamScore - OpponentScore, 
  Fumbles = Fumbles - DefFumbles,
  TurnoverMargin = TotalTurnovers - DefTotalTurnovers,
  Intercepts = Interceptions - DefInterceptions,
  Rushing = FirstDownRush - DefFirstDownRush,
  PenYds = PenaltyYds - DefPenaltyYds)
```

```{r}
model1 <- lm(differential ~ Penalties + Fumbles + TurnoverMargin + Intercepts + Rushing + PenYds, data=logs)
summary(model1)
```
Somehow we get the same Residual standard error with or without Intercepts, and with all the other information there. (this was a mistake without Penalties).

Adding rushing brought the Residual standard error down to 16.31, but taking TurnoverMargin out bumps this value up about .05.(this was a mistake without Penalties).

Penalties + Fumbles + TurnoverMargin + Intercepts + Rushing + PenYds = 16.28 (this is the lowest I have been able to get my Residual standard error).

Rushing has a significant effect on the model.

About 50% of the listed data (Penalties + Fumbles + TurnoverMargin + Intercepts + Rushing + PenYds) can be attributed to explaining the score differential.

##College Football Game Data Analysis (part 3 - Narrowing the data)

```{r}
closegames <- logs |> 
     filter(
         differential < 10)
```

Summary: 

There is definitely significance in the correlation between the scoring differential and penalties. Penalties alone is not a sole predictor of the scoring differential, nor are Fumbles + TurnoverMargin + Intercepts + Rushing + PenYds perfect predictors. Though together there is a minimization in the residual standard error off from the data. Together these aspects are stronger, but there still is a 50% explanation as to what can account for the score differential. This is high, which means were getting close, but I believe that there may be other aspects I'm not thinking of or don't quite understand enough to include. As for the filtering, I think this data could give more of a story when I solve how to do this. When a game is close, this is where aspects such as turnovers and penalties can make or break a game.

##Waffle Charts
Use for comparisons (two things)
```{r}
library("waffle")
```

```{r}
md <- c("Rushing"=175, "Passing"=314)
ms <- c("Rushing"=100, "Passing"=221)
```

```{r}
waffle(
        md, 
        rows = 10, 
        title="Maryland's offense", 
        xlab="1 square = 1 yard", 
        colors = c("black", "red")
)
```
waffle iron = comapres two charts. but lok what happened here, Michigan State is deceptively than showing that it has the same yardage in comaprison to Maryland, which is not true. So after this chart we'll show how to fix this with white space.
```{r}
iron(
 waffle(md, 
        rows = 10, 
        title="Maryland's offense", 
        xlab="1 square = 1 yard", 
        colors = c("black", "red")
        ),
 waffle(ms, 
        rows = 10, 
        title="Michigan State's offense", 
        xlab="1 square = 1 yard", 
        colors = c("black", "green")
        )
)
```
Here's how we fix the previous waffle iron. 
```{r}
md <- c("Rushing"=175, "Passing"=314)
ms <- c("Rushing"=100, "Passing"=221, 168)
```

```{r}
iron(
 waffle(md, 
        rows = 10, 
        title="Maryland's offense", 
        xlab="1 square = 1 yard", 
        colors = c("black", "red")
        ),
 waffle(ms, 
        rows = 10, 
        title="Michigan State's offense", 
        xlab="1 square = 1 yard",
        colors = c("black", "green", "white")
        )
)
```

Are the blocks too small? Lets make the squares larger
```{r}
iron(
 waffle(md/2, 
        rows = 10, 
        title="Maryland's offense", 
        xlab="1 square = 2 yards", 
        colors = c("black", "red")
        ),
 waffle(ms/2, 
        rows = 10, 
        title="Michigan State's offense", 
        xlab="1 square = 2 yards",
        colors = c("black", "green", "white")
        )
)
```


##Bump Charts
```{r}
rankings <- read_csv("https://thescoop.org/sports-data-files/cfbranking22.csv")
```
```{r}
head(rankings)
```
```{r}
ggplot() + 
  geom_bump(
    data=rankings, aes(x=Week, y=Rank, color=Team))
```

```{r}
top10 <- rankings |> filter(Week == 15 & Rank <= 10)

newrankings <- rankings |> filter(Team %in% top10$Team)
```

```{r}
ggplot() + 
  geom_bump(
    data=newrankings, aes(x=Week, y=Rank, color=Team))
```

```{r}
ggplot() + 
  geom_bump(
    data=newrankings, aes(x=Week, y=Rank, color=Team)) + 
  scale_y_reverse()
```

```{r}
ggplot() + 
  geom_bump(data=newrankings, aes(x=Week, y=Rank, color=Team)) + 
  geom_point(data=newrankings, aes(x=Week, y=Rank, color=Team), size = 4) +
  scale_y_reverse() 
```

```{r}
ggplot() + 
  geom_bump(data=newrankings, aes(x=Week, y=Rank, color=Team)) + 
  geom_point(data=newrankings, aes(x=Week, y=Rank, color=Team), size = 4) +   
  geom_text(data = newrankings |> filter(Week == min(Week)), aes(x = Week - .2, y=Rank, label = Team), size = 3, hjust = 1) +
  geom_text(data = newrankings |> filter(Week == max(Week)), aes(x = Week + .2, y=Rank, label = Team), size = 3, hjust = 0) +
  scale_color_manual(values = c("#9E1B32","#F56600", "#BA0C2F", "#0021A5", "#ffcb05", "#BB0000", "#4d1979","#FF8200", "#990000", "#CC0000")) +
  scale_y_reverse() 
```
to find these colors search up "Sports Hex Codes"

 
```{r, fig.width=X}
ggplot() + 
  geom_bump(data=newrankings, aes(x=Week, y=Rank, color=Team)) + 
  geom_point(data=newrankings, aes(x=Week, y=Rank, color=Team), size = 4) +   
  geom_text(data = newrankings |> filter(Week == min(Week)), aes(x = Week - .2, y=Rank, label = Team), size = 3, hjust = 1) +
  geom_text(data = newrankings |> filter(Week == max(Week)), aes(x = Week + .2, y=Rank, label = Team), size = 3, hjust = 0) +
  labs(title="Last year's top ten was anything but boring", subtitle="", y= "Rank", x = "Week") +
  theme_minimal() +
  theme(
    legend.position = "none",
    panel.grid.major = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 8), 
    plot.subtitle = element_text(size=10), 
    panel.grid.minor = element_blank()
    ) +
  scale_color_manual(values = c("#9E1B32","#F56600", "#BA0C2F", "#0021A5", "#ffcb05", "#BB0000", "#4d1979","#FF8200", "#990000", "#CC0000")) +
  scale_y_reverse() 
```

```{r, fig.width=X}
ggplot() + 
  geom_bump(data=newrankings, aes(x=Week, y=Rank, color=Team)) + 
  geom_point(data=newrankings, aes(x=Week, y=Rank, color=Team), size = 4) +   
  geom_text(data = newrankings |> filter(Week == min(Week)), aes(x = Week - .2, y=Rank, label = Team), size = 3, hjust = 1) +
  geom_text(data = newrankings |> filter(Week == max(Week)), aes(x = Week + .2, y=Rank, label = Team), size = 3, hjust = 0) +
  labs(title="Last year's top ten was anything but boring", subtitle="", y= "Rank", x = "Week") +
  theme_minimal() +
  theme(
    legend.position = "none",
    panel.grid.major = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 8), 
    plot.subtitle = element_text(size=10), 
    panel.grid.minor = element_blank()
    ) +
  scale_color_manual(values = c("#9E1B32","#F56600", "#BA0C2F", "#0021A5", "#ffcb05", "#BB0000", "#4d1979","#FF8200", "#990000", "#CC0000")) +
  scale_x_continuous(breaks=c(13,14,15,16,17)) + 
  scale_y_reverse(breaks=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))
```

